---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: '3'

# Taskfile used to manage certain VolSync tasks for a given application, limitations are as followed.
#   1. Fluxtomization, HelmRelease, PVC, ReplicationSource all have the same name (e.g. plex)
#   2. ReplicationSource and ReplicationDestination are a Restic repository
#   3. Applications are deployed as either a Kubernetes Deployment or StatefulSet
#   4. Each application only has one PVC that is being replicated

vars:
  VOLSYNC_RESOURCES_DIR: '{{.ROOT_DIR}}/.taskfiles/volsync/resources'

tasks:

  state-*:
    desc: Suspend or resume Volsync
    cmds:
      - flux --namespace flux-system {{.STATE}} kustomization volsync
      - flux --namespace volsync-system {{.STATE}} helmrelease volsync
      - kubectl --namespace volsync-system scale deployment volsync --replicas {{if eq .STATE "suspend"}}0{{else}}1{{end}}
    vars:
      STATE: '{{index .MATCH 0}}'
    preconditions:
      - '[[ "{{.STATE}}" == "suspend" || "{{.STATE}}" == "resume" ]]'
      - which flux kubectl

  list:
    desc: List all snapshots [NS=default] [APP=required] [LOC=-b2]
    summary: |
      Args:
        cluster: Cluster to run command against (required)
        ns: Namespace the PVC is in (default: default)
        app: Application to list snapshots for (required)
        loc: Location of the restic repository (default: blank for local)
    cmds:
      - minijinja-cli {{.VOLSYNC_RESOURCES_DIR}}/list.yaml.j2 | kubectl apply --server-side --filename -
      - until kubectl --namespace {{.NS}} get job/{{.JOB}} &>/dev/null; do sleep 5; done
      - kubectl --namespace {{.NS}} wait job/{{.JOB}} --for condition=complete --timeout=1m
      - kubectl --namespace {{.NS}} logs job/{{.JOB}} --container list
      - kubectl --namespace {{.NS}} delete job {{.JOB}}
    vars:
      NS: '{{.NS | default "default"}}'
      JOB: '{{.APP}}-list-snapshots'
      LOC: '{{.LOC | default ""}}'
    env:
      APP: '{{.APP}}'
      NS: '{{.NS}}'
      LOC: '{{.LOC}}'
    preconditions:
      - test -f {{.VOLSYNC_RESOURCES_DIR}}/list.yaml.j2
      - which flux kubectl minijinja-cli
    requires:
      vars: [APP]
    silent: true

  # To run backup jobs in parallel for all replicationsources:
  #  - kubectl get replicationsources --all-namespaces --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'task volsync:snapshot APP=$0 NS=$1'
  snapshot:
    desc: Snapshot an app [NS=default] [APP=required]
    cmds:
      - kubectl --namespace {{.NS}} patch replicationsources {{.APP}} --type merge -p '{"spec":{"trigger":{"manual":"{{now | unixEpoch}}"}}}'
      - until kubectl --namespace {{.NS}} get job/{{.JOB}} &>/dev/null; do sleep 5; done
      - kubectl --namespace {{.NS}} wait job/{{.JOB}} --for=condition=complete --timeout=120m
    vars:
      NS: '{{.NS | default "default"}}'
      JOB: volsync-src-{{.APP}}
    requires:
      vars: [APP]
    preconditions:
      - kubectl --namespace {{.NS}} get replicationsources {{.APP}}
      - which kubectl

  # To run restore jobs in parallel for all replicationdestinations:
  #   - kubectl get replicationsources --all-namespaces --no-headers | awk '{print $2, $1}' | xargs -l bash -c 'task volsync:restore app=$0 ns=$1'
  restore:
    desc: Restore an app [NS=default] [APP=required] [LOC=-b2] [PREVIOUS=required]
    cmds:
      # Suspend
      - flux --namespace {{.NS}} suspend kustomization {{.APP}}
      - flux --namespace {{.NS}} suspend helmrelease {{.APP}}
      - kubectl --namespace {{.NS}} scale {{.CONTROLLER}}/{{.APP}} --replicas 0
      - kubectl --namespace {{.NS}} wait pod --for=delete --selector="app.kubernetes.io/name={{.APP}}" --timeout=5m
      # Restore
      - minijinja-cli {{.VOLSYNC_RESOURCES_DIR}}/replicationdestination.yaml.j2 | kubectl apply --server-side --filename -
      - until kubectl --namespace {{.NS}} get job/volsync-dst-{{.APP}}-manual &>/dev/null; do sleep 5; done
      - kubectl --namespace {{.NS}} wait job/volsync-dst-{{.APP}}-manual --for=condition=complete --timeout=120m
      - kubectl --namespace {{.NS}} delete replicationdestination {{.APP}}-manual
      # Resume
      - flux --namespace {{.NS}} resume kustomization {{.APP}}
      - flux --namespace {{.NS}} resume helmrelease {{.APP}}
      - flux --namespace {{.NS}} reconcile helmrelease {{.APP}} --force
      - kubectl --namespace {{.NS}} wait pod --for=condition=ready --selector="app.kubernetes.io/name={{.APP}}" --timeout=5m
    vars:
      NS: '{{.NS | default "default"}}'
      LOC: '{{.LOC | default ""}}'
      CONTROLLER:
        sh: kubectl --namespace {{.NS}} get deployment {{.APP}} &>/dev/null && echo deployment || echo statefulset
    env:
      NS: '{{.NS}}'
      APP: '{{.APP}}'
      LOC: '{{.LOC}}'
      PREVIOUS: '{{.PREVIOUS}}'
      CLAIM:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.sourcePVC}'
      ACCESS_MODES:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.accessModes}'
      STORAGE_CLASS_NAME:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.storageClassName}'
      PUID:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.moverSecurityContext.runAsUser}'
      PGID:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.moverSecurityContext.runAsGroup}'
    requires:
      vars: [APP, PREVIOUS]
    preconditions:
      - test -f {{.VOLSYNC_RESOURCES_DIR}}/replicationdestination.yaml.j2
      - which flux kubectl minijinja-cli

  unlock:
    desc: Unlock all restic source repos
    cmds:
      - for: { var: SOURCES, split: "\n" }
        cmd: kubectl --namespace {{splitList "," .ITEM | first}} patch --field-manager=flux-client-side-apply replicationsources {{splitList "," .ITEM | last}} --type merge --patch "{\"spec\":{\"restic\":{\"unlock\":\"{{now | unixEpoch}}\"}}}"
    vars:
      SOURCES:
        sh: kubectl get replicationsources --all-namespaces --no-headers --output=jsonpath='{range .items[*]}{.metadata.namespace},{.metadata.name}{"\n"}{end}'
    preconditions:
      - which kubectl

  unlock-local:
    desc: Unlock a restic source repo from local machine [NS=default] [APP=required]
    cmds:
      - minijinja-cli {{.VOLSYNC_RESOURCES_DIR}}/unlock.yaml.j2 | kubectl apply --server-side --filename -
      - until kubectl --namespace {{.NS}} get job/volsync-unlock-{{.APP}} &>/dev/null; do sleep 5; done
      - kubectl --namespace {{.NS}} wait job/volsync-unlock-{{.APP}} --for condition=complete --timeout=5m
      - stern --namespace {{.NS}} job/volsync-unlock-{{.APP}} --no-follow
      - kubectl --namespace {{.NS}} delete job volsync-unlock-{{.APP}}
    vars:
      NS: '{{.NS | default "default"}}'
    env:
      NS: '{{.NS}}'
      APP: '{{.APP}}'
    requires:
      vars: [APP]
    preconditions:
      - test -f {{.VOLSYNC_RESOURCES_DIR}}/unlock.yaml.j2
      - which kubectl minijinja-cli stern

  migrate-pvc:
    desc: Restore an app [NS=default] [APP=required] [LOC=-b2] [PREVIOUS=required] [STORAGE_CLASS_NAME=ceph-ssd]
    cmds:
      # Pause KEDA
      - |
        if kubectl --namespace {{.NS}} get scaledobject {{.APP}} &>/dev/null; then
          kubectl --namespace {{.NS}} annotate scaledobject {{.APP}} autoscaling.keda.sh/paused="true" --overwrite
        else
          echo "No ScaledObject found for {{.APP}}, skipping pause."
        fi
      # Suspend
      - flux --namespace {{.NS}} suspend kustomization {{.APP}}
      - flux --namespace {{.NS}} suspend helmrelease {{.APP}}
      - kubectl --namespace {{.NS}} scale {{.CONTROLLER}}/{{.APP}} --replicas 0
      - kubectl --namespace {{.NS}} wait pod --for=delete --selector="app.kubernetes.io/name={{.APP}}" --timeout=5m
      # Restore (ReplicationDestination with Snapshot)
      - minijinja-cli {{.VOLSYNC_RESOURCES_DIR}}/replicationdestinationmigration.yaml.j2 | kubectl apply --server-side --filename -
      - until kubectl --namespace {{.NS}} get job/volsync-dst-{{.APP}}-manual &>/dev/null; do sleep 5; done
      - kubectl --namespace {{.NS}} wait job/volsync-dst-{{.APP}}-manual --for=condition=complete --timeout=120m
      # Delete old PVC (free the name, keep PV intact)
      - kubectl --namespace {{.NS}} delete pvc {{.APP}}
      - kubectl --namespace {{.NS}} wait --for=delete pvc/{{.APP}} --timeout=60s
      # Create new PVC with same name but ceph-ssd + dataSourceRef
      - minijinja-cli {{.VOLSYNC_RESOURCES_DIR}}/pvc-migrate.yaml.j2 | kubectl create --filename -
      # Clean up ReplicationDestination
      - kubectl --namespace {{.NS}} delete replicationdestination {{.APP}}-manual
      # Temporary patch until github change is committed and restart pods
      - kubectl patch pvc {{.APP}} -n {{.NS}} --type merge -p '{"spec":{"storageClassName":"ceph-ssd"}}'
      - flux --namespace {{.NS}} resume helmrelease {{.APP}}
      - kubectl --namespace {{.NS}} scale {{.CONTROLLER}}/{{.APP}} --replicas 1
      - kubectl --namespace {{.NS}} rollout restart {{.CONTROLLER}}/{{.APP}}
      - kubectl --namespace {{.NS}} rollout status {{.CONTROLLER}}/{{.APP}} --timeout=5m
      # Resume KEDA
      - |
        if kubectl --namespace {{.NS}} get scaledobject {{.APP}} &>/dev/null; then
          kubectl --namespace {{.NS}} annotate scaledobject {{.APP}} autoscaling.keda.sh/paused- --overwrite
        else
          echo "No ScaledObject found for {{.APP}}, skipping resume."
        fi

    vars:
      NS: '{{.NS | default "default"}}'
      LOC: '{{.LOC | default ""}}'
      STORAGE_CLASS_NAME: '{{.STORAGE_CLASS_NAME | default "ceph-ssd"}}'
      CONTROLLER:
        sh: kubectl --namespace {{.NS}} get deployment {{.APP}} &>/dev/null && echo deployment || echo statefulset
    env:
      NS: '{{.NS}}'
      APP: '{{.APP}}'
      LOC: '{{.LOC}}'
      PREVIOUS: '{{.PREVIOUS}}'
      CLAIM:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.sourcePVC}'
      ACCESS_MODES:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.accessModes}'
      STORAGE_CLASS_NAME: '{{.STORAGE_CLASS_NAME}}'
      SIZE:
        sh: kubectl --namespace {{.NS}} get pvc {{.APP}} --output=jsonpath='{.spec.resources.requests.storage}'
      PUID:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.moverSecurityContext.runAsUser}'
      PGID:
        sh: kubectl --namespace {{.NS}} get replicationsources/{{.APP}} --output=jsonpath='{.spec.restic.moverSecurityContext.runAsGroup}'
    requires:
      vars: [APP, PREVIOUS]
    preconditions:
      - test -f {{.VOLSYNC_RESOURCES_DIR}}/replicationdestinationmigration.yaml.j2
      - test -f {{.VOLSYNC_RESOURCES_DIR}}/pvc-migrate.yaml.j2
      - which flux kubectl minijinja-cli
